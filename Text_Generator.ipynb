{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generator.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO2V+vk8+2vp3L0UZAHyLLD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antnewman/nlp-textgenerator-gpt2-notebook/blob/main/Text_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHBWIhFWqHBg"
      },
      "source": [
        "# Text Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCJkCmadqEed"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "!pip install -q gpt-2-simple\r\n",
        "import gpt_2_simple as gpt2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic5dQ-IEr0CD"
      },
      "source": [
        "There are three released sizes of GPT-2:\r\n",
        "- 124M (default): the \"small\" model, 500MB on disk.\r\n",
        "- 355M: the \"medium\" model, 1.5GB on disk.\r\n",
        "- 774M: the \"large\" model\r\n",
        "- 1558M: the \"extra large\"\r\n",
        "\r\n",
        "The large model cannot currently be finetuned with Colaboratory but can be used to generate text from a pretrained model.\r\n",
        "\r\n",
        "The extra large is the true model. It will not work if a K80/P4 GPU is attached to the notebook and as with the large model, it cannot be finetuned.\r\n",
        "\r\n",
        "The larger the model, the greater the knowledge but the longer the processing time. \r\n",
        "\r\n",
        "Use *model_name* to cahnge the base model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk2nMu8_qwFD"
      },
      "source": [
        "# Check GPU\r\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkyLjeNFswC7"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}